import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

# Configuration des graphiques
plt.style.use('default')
sns.set_palette("husl")

# ==========================================
# CONFIGURATION - FICHIERS DE RÃ‰FÃ‰RENCE
# ==========================================

# Fichiers principaux aprÃ¨s corrections
PARIS_FILE = "data/processed/enriched_paris_fixed.csv"
SEATTLE_FILE = "data/processed/enriched_seattle_fixed.csv"

# Dossier de sortie pour les rÃ©sultats
OUTPUT_DIR = "results/ml_baseline/"
import os
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(f"{OUTPUT_DIR}/plots/", exist_ok=True)

def explore_data_structure():
    """
    Explore la structure des donnÃ©es pour identifier les bonnes colonnes
    """
    print("ğŸ” EXPLORATION DE LA STRUCTURE DES DONNÃ‰ES")
    print("="*70)
    
    # Chargement des fichiers
    df_paris = pd.read_csv(PARIS_FILE)
    df_seattle = pd.read_csv(SEATTLE_FILE)
    
    print(f"âœ… Paris : {df_paris.shape[0]:,} lignes Ã— {df_paris.shape[1]} colonnes")
    print(f"âœ… Seattle : {df_seattle.shape[0]:,} lignes Ã— {df_seattle.shape[1]} colonnes")
    
    # Recherche des colonnes pertinentes
    print("\nğŸ” Recherche des features ML dans Paris...")
    paris_cols = df_paris.columns.tolist()
    
    # Recherche par mots-clÃ©s
    occupancy_cols = [col for col in paris_cols if 'occup' in col.lower()]
    price_cols = [col for col in paris_cols if 'price' in col.lower()]
    rating_cols = [col for col in paris_cols if 'rating' in col.lower() or 'score' in col.lower()]
    amenity_cols = [col for col in paris_cols if 'amenity' in col.lower() or 'amenities' in col.lower()]
    temporal_cols = [col for col in paris_cols if col in ['month', 'day_of_week', 'year', 'day']]
    
    print(f"  ğŸ“Š Occupancy-related: {occupancy_cols[:3]}...")
    print(f"  ğŸ’° Price-related: {price_cols[:3]}...")
    print(f"  â­ Rating-related: {rating_cols[:3]}...")
    print(f"  ğŸ  Amenity-related: {amenity_cols[:3]}...")
    print(f"  ğŸ“… Temporal: {temporal_cols}")
    
    print("\nğŸ” Recherche des features ML dans Seattle...")
    seattle_cols = df_seattle.columns.tolist()
    
    seattle_occupancy = [col for col in seattle_cols if 'occup' in col.lower()]
    seattle_price = [col for col in seattle_cols if 'price' in col.lower()]
    seattle_rating = [col for col in seattle_cols if 'rating' in col.lower() or 'score' in col.lower()]
    seattle_amenity = [col for col in seattle_cols if 'amenity' in col.lower() or 'amenities' in col.lower()]
    seattle_temporal = [col for col in seattle_cols if col in ['month', 'day_of_week', 'year', 'day']]
    
    print(f"  ğŸ“Š Occupancy-related: {seattle_occupancy[:3]}...")
    print(f"  ğŸ’° Price-related: {seattle_price[:3]}...")
    print(f"  â­ Rating-related: {seattle_rating[:3]}...")
    print(f"  ğŸ  Amenity-related: {seattle_amenity[:3]}...")
    print(f"  ğŸ“… Temporal: {seattle_temporal}")
    
    # Retourner les datasets et les colonnes identifiÃ©es
    feature_mapping = {
        'paris': {
            'occupancy': occupancy_cols[0] if occupancy_cols else None,
            'price': price_cols[0] if price_cols else None,
            'rating': rating_cols[0] if rating_cols else None,
            'amenities': amenity_cols[0] if amenity_cols else None,
            'month': 'month' if 'month' in paris_cols else None,
            'day_of_week': 'day_of_week' if 'day_of_week' in paris_cols else None
        },
        'seattle': {
            'occupancy': seattle_occupancy[0] if seattle_occupancy else None,
            'price': seattle_price[0] if seattle_price else None,
            'rating': seattle_rating[0] if seattle_rating else None,
            'amenities': seattle_amenity[0] if seattle_amenity else None,
            'month': 'month' if 'month' in seattle_cols else None,
            'day_of_week': 'day_of_week' if 'day_of_week' in seattle_cols else None
        }
    }
    
    return df_paris, df_seattle, feature_mapping

def create_ml_features(df_paris, df_seattle, feature_mapping):
    """
    CrÃ©e les features ML standardisÃ©es
    """
    print("\nğŸ¯ CRÃ‰ATION DES FEATURES ML STANDARDISÃ‰ES")
    print("="*70)
    
    # Fonction pour crÃ©er les features d'une ville
    def prepare_city_data(df, city, mapping):
        print(f"\nğŸ™ï¸  Traitement {city}...")
        
        df_ml = df.copy()
        df_ml['city'] = city
        
        # Mapping des colonnes vers des noms standardisÃ©s
        column_map = {}
        
        if mapping['occupancy']:
            column_map[mapping['occupancy']] = 'occupancy_rate'
            print(f"  ğŸ“Š Occupancy: {mapping['occupancy']} â†’ occupancy_rate")
        
        if mapping['price']:
            column_map[mapping['price']] = 'revenue'
            print(f"  ğŸ’° Price: {mapping['price']} â†’ revenue")
        
        if mapping['rating']:
            column_map[mapping['rating']] = 'sentiment_score'
            print(f"  â­ Rating: {mapping['rating']} â†’ sentiment_score")
        
        if mapping['amenities']:
            column_map[mapping['amenities']] = 'nb_amenities'
            print(f"  ğŸ  Amenities: {mapping['amenities']} â†’ nb_amenities")
        
        # Renommer les colonnes
        df_ml = df_ml.rename(columns=column_map)
        
        # VÃ©rifier les colonnes temporelles
        temporal_cols = ['month', 'day_of_week']
        for col in temporal_cols:
            if col in df_ml.columns:
                print(f"  ğŸ“… Temporal: {col} âœ…")
            else:
                print(f"  ğŸ“… Temporal: {col} âŒ")
        
        # SÃ©lectionner les colonnes finales disponibles
        target_cols = ['occupancy_rate', 'revenue', 'sentiment_score', 'nb_amenities', 'month', 'day_of_week', 'city']
        available_cols = [col for col in target_cols if col in df_ml.columns]
        
        df_final = df_ml[available_cols].copy()
        
        print(f"  âœ… Features disponibles: {len(available_cols)-1}/6")
        print(f"  ğŸ“Š Dimensions finales: {df_final.shape}")
        
        return df_final
    
    # Traitement des deux villes
    df_paris_ml = prepare_city_data(df_paris, 'Paris', feature_mapping['paris'])
    df_seattle_ml = prepare_city_data(df_seattle, 'Seattle', feature_mapping['seattle'])
    
    # Combinaison des datasets
    df_combined = pd.concat([df_paris_ml, df_seattle_ml], ignore_index=True)
    
    print(f"\nâœ… Dataset combinÃ©: {df_combined.shape[0]:,} lignes Ã— {df_combined.shape[1]} colonnes")
    
    # Affichage du rÃ©sumÃ© des features
    print(f"\nğŸ“‹ RÃ‰SUMÃ‰ DES FEATURES:")
    for col in df_combined.columns:
        if col != 'city':
            missing_pct = df_combined[col].isnull().sum() / len(df_combined) * 100
            unique_vals = df_combined[col].nunique()
            print(f"  â€¢ {col}: {unique_vals} valeurs uniques, {missing_pct:.1f}% manquantes")
    
    return df_combined

def prepare_ml_targets(df_combined):
    """
    PrÃ©pare les variables cibles
    """
    print(f"\nğŸ¯ PRÃ‰PARATION DES VARIABLES CIBLES")
    print("="*70)
    
    # Variable cible rÃ©gression : revenue (price)
    if 'revenue' in df_combined.columns:
        y_regression = df_combined['revenue'].copy()
        print(f"âœ… RÃ©gression target: revenue")
        print(f"  â€¢ Min: ${y_regression.min():.2f}")
        print(f"  â€¢ Max: ${y_regression.max():.2f}")
        print(f"  â€¢ Moyenne: ${y_regression.mean():.2f}")
        print(f"  â€¢ Valeurs manquantes: {y_regression.isnull().sum()}")
    else:
        print("âŒ Pas de variable revenue trouvÃ©e")
        y_regression = None
    
    # Variable cible classification : "bien notÃ©" vs "mal notÃ©"
    if 'sentiment_score' in df_combined.columns:
        sentiment_col = df_combined['sentiment_score']
        
        # DÃ©terminer le seuil automatiquement selon l'Ã©chelle
        max_score = sentiment_col.max()
        
        if max_score <= 5:  # Ã‰chelle 1-5
            threshold = 4.5
            y_classification = (sentiment_col >= threshold).astype(int)
            print(f"âœ… Classification target: sentiment_score >= {threshold} (Ã©chelle 1-5)")
        elif max_score <= 100:  # Ã‰chelle 1-100
            threshold = 80
            y_classification = (sentiment_col >= threshold).astype(int)
            print(f"âœ… Classification target: sentiment_score >= {threshold} (Ã©chelle 1-100)")
        else:
            threshold = sentiment_col.median()
            y_classification = (sentiment_col >= threshold).astype(int)
            print(f"âœ… Classification target: sentiment_score >= {threshold:.2f} (mÃ©diane)")
        
        # Statistiques classification
        class_counts = y_classification.value_counts()
        print(f"  â€¢ Mal notÃ© (0): {class_counts.get(0, 0):,} ({class_counts.get(0, 0)/len(y_classification)*100:.1f}%)")
        print(f"  â€¢ Bien notÃ© (1): {class_counts.get(1, 0):,} ({class_counts.get(1, 0)/len(y_classification)*100:.1f}%)")
        
    else:
        print("âŒ Pas de variable sentiment_score trouvÃ©e")
        y_classification = None
    
    return y_regression, y_classification

def preprocess_features(df_combined):
    """
    Preprocessing des features
    """
    print(f"\nğŸ”§ PREPROCESSING DES FEATURES")
    print("="*70)
    
    # PrÃ©parer X en excluant les targets
    exclude_cols = ['revenue', 'sentiment_score']
    X_cols = [col for col in df_combined.columns if col not in exclude_cols]
    X = df_combined[X_cols].copy()
    
    print(f"ğŸ“Š Features pour ML: {X.columns.tolist()}")
    
    # Encodage city si prÃ©sent
    if 'city' in X.columns:
        le = LabelEncoder()
        X['city_encoded'] = le.fit_transform(X['city'].fillna('Unknown'))
        X = X.drop('city', axis=1)
        print(f"âœ… City encodÃ©: {X['city_encoded'].nunique()} valeurs")
    
    # Gestion valeurs manquantes
    print(f"\nğŸ“Š Valeurs manquantes:")
    missing_info = X.isnull().sum()
    for col, missing in missing_info.items():
        if missing > 0:
            print(f"  â€¢ {col}: {missing} ({missing/len(X)*100:.1f}%)")
    
    # Imputation
    imputer = SimpleImputer(strategy='median')
    X_imputed = pd.DataFrame(
        imputer.fit_transform(X),
        columns=X.columns,
        index=X.index
    )
    
    print(f"âœ… Imputation terminÃ©e")
    
    # Normalisation
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(
        scaler.fit_transform(X_imputed),
        columns=X_imputed.columns,
        index=X_imputed.index
    )
    
    print(f"âœ… Normalisation terminÃ©e")
    print(f"âœ… Features finales: {X_scaled.columns.tolist()}")
    
    return X_scaled

def train_models(X, y_reg, y_clf):
    """
    EntraÃ®ne les modÃ¨les baseline
    """
    print(f"\nğŸ¤– ENTRAÃNEMENT DES MODÃˆLES BASELINE")
    print("="*70)
    
    results = {}
    
    # RÃ‰GRESSION
    if y_reg is not None and not y_reg.isnull().all():
        print(f"\nğŸ“Š RÃ‰GRESSION (PrÃ©diction Prix)")
        print("-" * 40)
        
        # Nettoyer les donnÃ©es pour la rÃ©gression
        mask_reg = ~y_reg.isnull()
        X_reg = X[mask_reg]
        y_reg_clean = y_reg[mask_reg]
        
        # Split
        X_train, X_test, y_train, y_test = train_test_split(
            X_reg, y_reg_clean, test_size=0.2, random_state=42
        )
        
        print(f"  ğŸ“Š Train: {X_train.shape[0]:,} | Test: {X_test.shape[0]:,}")
        
        # RÃ©gression LinÃ©aire
        lr = LinearRegression()
        lr.fit(X_train, y_train)
        y_pred_lr = lr.predict(X_test)
        
        rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
        r2_lr = r2_score(y_test, y_pred_lr)
        cv_lr = cross_val_score(lr, X_train, y_train, cv=5, scoring='r2')
        
        print(f"  ğŸ”¸ RÃ©gression LinÃ©aire:")
        print(f"    â€¢ RMSE: ${rmse_lr:.2f}")
        print(f"    â€¢ RÂ²: {r2_lr:.3f}")
        print(f"    â€¢ CV RÂ²: {cv_lr.mean():.3f}Â±{cv_lr.std():.3f}")
        
        # Random Forest
        rf = RandomForestRegressor(n_estimators=100, random_state=42)
        rf.fit(X_train, y_train)
        y_pred_rf = rf.predict(X_test)
        
        rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
        r2_rf = r2_score(y_test, y_pred_rf)
        cv_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring='r2')
        
        print(f"  ğŸŒ² Random Forest:")
        print(f"    â€¢ RMSE: ${rmse_rf:.2f}")
        print(f"    â€¢ RÂ²: {r2_rf:.3f}")
        print(f"    â€¢ CV RÂ²: {cv_rf.mean():.3f}Â±{cv_rf.std():.3f}")
        
        results['regression'] = {
            'LinearRegression': {'rmse': rmse_lr, 'r2': r2_lr, 'cv_mean': cv_lr.mean(), 'cv_std': cv_lr.std()},
            'RandomForest': {'rmse': rmse_rf, 'r2': r2_rf, 'cv_mean': cv_rf.mean(), 'cv_std': cv_rf.std()},
            'test_data': (X_test, y_test, y_pred_lr, y_pred_rf)
        }
    
    # CLASSIFICATION
    if y_clf is not None and not y_clf.isnull().all():
        print(f"\nğŸ¯ CLASSIFICATION (Bien notÃ© vs Mal notÃ©)")
        print("-" * 40)
        
        # Nettoyer les donnÃ©es pour la classification
        mask_clf = ~y_clf.isnull()
        X_clf = X[mask_clf]
        y_clf_clean = y_clf[mask_clf]
        
        if y_clf_clean.nunique() > 1:  # VÃ©rifier qu'il y a au moins 2 classes
            # Split stratifiÃ©
            X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
                X_clf, y_clf_clean, test_size=0.2, random_state=42, stratify=y_clf_clean
            )
            
            # Random Forest Classifier
            rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
            rf_clf.fit(X_train_clf, y_train_clf)
            y_pred_clf = rf_clf.predict(X_test_clf)
            
            accuracy = rf_clf.score(X_test_clf, y_test_clf)
            cv_clf = cross_val_score(rf_clf, X_train_clf, y_train_clf, cv=5)
            
            print(f"  ğŸŒ² Random Forest Classifier:")
            print(f"    â€¢ Accuracy: {accuracy:.3f}")
            print(f"    â€¢ CV Accuracy: {cv_clf.mean():.3f}Â±{cv_clf.std():.3f}")
            
            # Matrice de confusion
            cm = confusion_matrix(y_test_clf, y_pred_clf)
            print(f"  ğŸ“Š Matrice de confusion:")
            print(f"       PrÃ©diction")
            print(f"    RÃ©el  0   1")
            print(f"      0  {cm[0,0]:3d} {cm[0,1]:3d}")
            print(f"      1  {cm[1,0]:3d} {cm[1,1]:3d}")
            
            results['classification'] = {
                'accuracy': accuracy,
                'cv_mean': cv_clf.mean(),
                'cv_std': cv_clf.std(),
                'confusion_matrix': cm,
                'test_data': (X_test_clf, y_test_clf, y_pred_clf)
            }
        else:
            print("  âš ï¸  Une seule classe dÃ©tectÃ©e - classification impossible")
    
    return results

def create_plots(results):
    """
    CrÃ©e les graphiques d'Ã©valuation
    """
    if not results:
        print("âš ï¸  Pas de rÃ©sultats Ã  visualiser")
        return
    
    print(f"\nğŸ“Š CRÃ‰ATION DES GRAPHIQUES")
    print("="*70)
    
    n_plots = len(results)
    fig, axes = plt.subplots(1, n_plots, figsize=(6*n_plots, 5))
    
    if n_plots == 1:
        axes = [axes]
    
    plot_idx = 0
    
    # Graphique rÃ©gression
    if 'regression' in results:
        ax = axes[plot_idx]
        X_test, y_test, y_pred_lr, y_pred_rf = results['regression']['test_data']
        
        ax.scatter(y_test, y_pred_lr, alpha=0.6, label=f"Linear Reg (RÂ²={results['regression']['LinearRegression']['r2']:.3f})")
        ax.scatter(y_test, y_pred_rf, alpha=0.6, label=f"Random Forest (RÂ²={results['regression']['RandomForest']['r2']:.3f})")
        
        min_val, max_val = y_test.min(), y_test.max()
        ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Parfait')
        
        ax.set_xlabel('Prix RÃ©el ($)')
        ax.set_ylabel('Prix PrÃ©dit ($)')
        ax.set_title('RÃ©gression: PrÃ©dictions vs RÃ©el')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plot_idx += 1
    
    # Graphique classification
    if 'classification' in results:
        ax = axes[plot_idx]
        cm = results['classification']['confusion_matrix']
        
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                   xticklabels=['Mal notÃ©', 'Bien notÃ©'],
                   yticklabels=['Mal notÃ©', 'Bien notÃ©'])
        ax.set_title(f"Classification (Acc: {results['classification']['accuracy']:.3f})")
        ax.set_xlabel('PrÃ©diction')
        ax.set_ylabel('RÃ©el')
    
    plt.tight_layout()
    plt.savefig(f"{OUTPUT_DIR}/plots/ml_baseline_results.png", dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… Graphiques sauvegardÃ©s: {OUTPUT_DIR}/plots/ml_baseline_results.png")

def generate_final_report(results):
    """
    GÃ©nÃ¨re le rapport final
    """
    print(f"\nğŸ“‹ GÃ‰NÃ‰RATION DU RAPPORT FINAL")
    print("="*70)
    
    report_lines = []
    report_lines.append("# ğŸ“Š RAPPORT ML BASELINE - JOUR 3")
    report_lines.append("=" * 50)
    report_lines.append("")
    
    # RÃ©sumÃ© exÃ©cutif
    report_lines.append("## ğŸ¯ RÃ‰SUMÃ‰ EXÃ‰CUTIF")
    report_lines.append("")
    
    if 'regression' in results:
        best_reg_r2 = max(results['regression']['LinearRegression']['r2'], 
                         results['regression']['RandomForest']['r2'])
        best_reg_model = 'Random Forest' if results['regression']['RandomForest']['r2'] > results['regression']['LinearRegression']['r2'] else 'Linear Regression'
        
        report_lines.append("### ğŸ“Š RÃ©gression (PrÃ©diction Prix)")
        report_lines.append("| ModÃ¨le | RMSE ($) | RÂ² | CV RÂ² |")
        report_lines.append("|--------|----------|----|----|")
        report_lines.append(f"| Linear Regression | ${results['regression']['LinearRegression']['rmse']:.2f} | {results['regression']['LinearRegression']['r2']:.3f} | {results['regression']['LinearRegression']['cv_mean']:.3f}Â±{results['regression']['LinearRegression']['cv_std']:.3f} |")
        report_lines.append(f"| Random Forest | ${results['regression']['RandomForest']['rmse']:.2f} | {results['regression']['RandomForest']['r2']:.3f} | {results['regression']['RandomForest']['cv_mean']:.3f}Â±{results['regression']['RandomForest']['cv_std']:.3f} |")
        report_lines.append("")
        report_lines.append(f"**ğŸ† Meilleur modÃ¨le**: {best_reg_model} (RÂ² = {best_reg_r2:.3f})")
        report_lines.append("")
    
    if 'classification' in results:
        report_lines.append("### ğŸ¯ Classification (Bien notÃ© vs Mal notÃ©)")
        report_lines.append("| MÃ©trique | Valeur |")
        report_lines.append("|----------|--------|")
        report_lines.append(f"| Accuracy | {results['classification']['accuracy']:.3f} |")
        report_lines.append(f"| CV Accuracy | {results['classification']['cv_mean']:.3f}Â±{results['classification']['cv_std']:.3f} |")
        report_lines.append("")
        
        cm = results['classification']['confusion_matrix']
        report_lines.append("**ğŸ“Š Matrice de confusion:**")
        report_lines.append("```")
        report_lines.append("           PrÃ©diction")
        report_lines.append("RÃ©el    Mal notÃ©  Bien notÃ©")
        report_lines.append(f"Mal notÃ©    {cm[0,0]:3d}      {cm[0,1]:3d}")
        report_lines.append(f"Bien notÃ©   {cm[1,0]:3d}      {cm[1,1]:3d}")
        report_lines.append("```")
        report_lines.append("")
    
    # Conclusions
    report_lines.append("## ğŸ¯ CONCLUSIONS ET PROCHAINES Ã‰TAPES")
    report_lines.append("")
    
    if 'regression' in results:
        best_r2 = max(results['regression']['LinearRegression']['r2'], 
                     results['regression']['RandomForest']['r2'])
        if best_r2 > 0.7:
            report_lines.append("âœ… **RÃ©gression**: Performance excellente - PrÃªt pour optimisation avancÃ©e")
        elif best_r2 > 0.5:
            report_lines.append("ğŸ”¶ **RÃ©gression**: Performance correcte - Feature engineering recommandÃ©")
        else:
            report_lines.append("âŒ **RÃ©gression**: Performance faible - Analyse approfondie nÃ©cessaire")
    
    if 'classification' in results:
        acc = results['classification']['accuracy']
        if acc > 0.85:
            report_lines.append("âœ… **Classification**: Performance excellente - PrÃªt pour optimisation")
        elif acc > 0.75:
            report_lines.append("ğŸ”¶ **Classification**: Performance correcte - Tuning recommandÃ©")
        else:
            report_lines.append("âŒ **Classification**: Performance faible - Revoir stratÃ©gie")
    
    # Sauvegarde
    with open(f"{OUTPUT_DIR}/ml_baseline_report.md", 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    
    print(f"âœ… Rapport sauvegardÃ©: {OUTPUT_DIR}/ml_baseline_report.md")
    
    # Affichage rÃ©sumÃ© console
    print(f"\nğŸ† RÃ‰SULTATS FINAUX")
    print("="*50)
    
    if 'regression' in results:
        best_reg_r2 = max(results['regression']['LinearRegression']['r2'], 
                         results['regression']['RandomForest']['r2'])
        best_reg_model = 'Random Forest' if results['regression']['RandomForest']['r2'] > results['regression']['LinearRegression']['r2'] else 'Linear Regression'
        print(f"ğŸ“Š RÃ‰GRESSION: {best_reg_model} - RÂ² = {best_reg_r2:.3f}")
    
    if 'classification' in results:
        print(f"ğŸ¯ CLASSIFICATION: Random Forest - Accuracy = {results['classification']['accuracy']:.3f}")
    
    print("="*50)

def main():
    """
    Fonction principale ML Baseline - Version corrigÃ©e
    """
    print("ğŸš€ JOUR 3 - ML BASELINE (VERSION CORRIGÃ‰E)")
    print("="*70)
    print("Objectif : Adapter aux donnÃ©es rÃ©elles et entraÃ®ner modÃ¨les baseline")
    print()
    
    try:
        # 1. Explorer la structure des donnÃ©es
        df_paris, df_seattle, feature_mapping = explore_data_structure()
        
        # 2. CrÃ©er les features ML
        df_combined = create_ml_features(df_paris, df_seattle, feature_mapping)
        
        # 3. PrÃ©parer les targets
        y_regression, y_classification = prepare_ml_targets(df_combined)
        
        # 4. Preprocessing
        X = preprocess_features(df_combined)
        
        # 5. EntraÃ®nement
        results = train_models(X, y_regression, y_classification)
        
        # 6. Visualisation
        create_plots(results)
        
        # 7. Rapport final
        generate_final_report(results)
        
        print(f"\nğŸ‰ ML BASELINE TERMINÃ‰ AVEC SUCCÃˆS !")
        print(f"ğŸ“ RÃ©sultats disponibles dans: {OUTPUT_DIR}")
        print(f"ğŸ“Š Fichiers crÃ©Ã©s:")
        print(f"  â€¢ {OUTPUT_DIR}/ml_baseline_report.md")
        print(f"  â€¢ {OUTPUT_DIR}/plots/ml_baseline_results.png")
        
    except Exception as e:
        print(f"\nâŒ Erreur durant le ML Baseline: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()